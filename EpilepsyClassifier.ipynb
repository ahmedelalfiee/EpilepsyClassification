{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import entropy\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sklearn.decomposition\n",
        "\n",
        "# Load EEG data\n",
        "df = pd.read_csv(\"EEG-data.csv\")\n"
      ],
      "metadata": {
        "id": "BezegrXhpJUW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data and select relevant features\n",
        "filtered_data = df[df['y'].isin([3, 4])]\n",
        "X = filtered_data.drop(['Unnamed: 0', 'y'], axis=1)  # Features\n",
        "y = filtered_data['y']  # Target\n"
      ],
      "metadata": {
        "id": "EtJHW8zYpNkv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform PCA with a high explained variance threshold\n",
        "pca = sklearn.decomposition.PCA(n_components=0.9999)\n",
        "\n",
        "# Transform the data to PCA space\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Reconstruct the original data from PCA space\n",
        "X_ori = pca.inverse_transform(X_pca)\n",
        "\n",
        "# Calculate anomaly scores\n",
        "anomaly_score = np.abs(X.to_numpy() - X_ori).sum(axis=1)\n",
        "\n",
        "# Set anomaly detection threshold\n",
        "threshold = np.quantile(anomaly_score, 0.99)\n",
        "\n",
        "# Find anomalous IDs\n",
        "anomalous_ids = np.argwhere(anomaly_score > threshold).squeeze()\n",
        "\n",
        "# Display anomalous IDs\n",
        "anomalous_ids\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyIkTl7v5XzL",
        "outputId": "1a9fd200-2aa4-4d8c-bfe7-f60655ea11a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33, 37])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the features\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n"
      ],
      "metadata": {
        "id": "A1TqiwJxsFfq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Fast Fourier Transform (FFT) of the data along the specified axis\n",
        "fft_data = np.abs(np.fft.fft(X, axis=1))\n"
      ],
      "metadata": {
        "id": "aMfdTKPEpZjj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fPRXHJ6Bo6Tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7722dde4-79b7-401a-da91-fbfa2abfff1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "# Define function to compute PSD features\n",
        "def compute_psd_features(fft_data, fs):\n",
        "    psd_features = []\n",
        "    freq_bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13), 'beta': (13, 30), 'gamma': (30, 70)}\n",
        "\n",
        "    for sample_fft in fft_data:\n",
        "        psd_values, psd_freqs = welch(sample_fft, fs=fs, nperseg=fs)\n",
        "        psd_band_values = {band: np.mean(psd_values[(psd_freqs >= f_low) & (psd_freqs < f_high)])\n",
        "                           for band, (f_low, f_high) in freq_bands.items()}\n",
        "        psd_features.append(psd_band_values)\n",
        "\n",
        "    return pd.DataFrame(psd_features)\n",
        "\n",
        "# Extract frequency-domain features\n",
        "fs = 1000  # Sampling frequency\n",
        "psd_df = compute_psd_features(fft_data, fs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaN values in the DataFrame with 0\n",
        "psd_df.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "0IdXfWZSrXVx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(psd_df, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0Mg2ujMJITer"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1)\n",
        "\n",
        "# Perform cross-validation\n",
        "accuracy_scores = cross_val_score(svm_classifier, psd_df, y, cv=5)\n",
        "\n",
        "# Calculate average accuracy\n",
        "average_accuracy = np.mean(accuracy_scores)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "# Fit the classifier on the entire dataset\n",
        "svm_classifier.fit(psd_df, y)\n",
        "\n",
        "# Predict on the last test set\n",
        "y_pred = svm_classifier.predict(x_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Calculate sensitivity and specificity\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n"
      ],
      "metadata": {
        "id": "uxhOnVMsBoBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bf7766-a4a3-4edd-d3bb-220c3e52fdf3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.875\n",
            "Sensitivity: 1.0\n",
            "Specificity: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = rf.predict(x_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Compute confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Calculate sensitivity and specificity\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n"
      ],
      "metadata": {
        "id": "5_eZYwPftVHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fd4476-7088-4b99-c364-61dddb8932c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Sensitivity: 0.96\n",
            "Specificity: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Naive Bayes classifier\n",
        "naive_bayes_classifier = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "naive_bayes_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = naive_bayes_classifier.predict(x_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Compute confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Calculate sensitivity and specificity\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)"
      ],
      "metadata": {
        "id": "CViKQGCjtm-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe7059a-5b5c-46eb-b7e9-105d679e791d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Sensitivity: 1.0\n",
            "Specificity: 0.7333333333333333\n"
          ]
        }
      ]
    }
  ]
}